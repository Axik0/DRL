{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258662a0-e281-4028-9efe-24265ffe5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -q -r requirements.txt\n",
    "# !pip install swig\n",
    "# !pip install gymnasium[box2d]\n",
    "# !pipreqsnb --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633e5088-1d71-4abd-bdd3-039562cddb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsummary as summary\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10053666-0f2e-4ff2-aa2b-e4c77bc4a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = gym.make(\"MountainCarContinuous-v0\", render_mode='rgb_array')\n",
    "SS = ENV.observation_space # continuous \n",
    "DIM_S = SS.shape[0] # 2-dimensional (position, velocity) continuous, [-inf, +inf] for both\n",
    "AS = ENV.action_space # finite action space, 4 actions\n",
    "DIM_A = AS.shape[0] # 1-dimensional continuous force within [-1, +1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdedb88-8fe2-4558-b93f-1ffb603b8a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.40667263,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stochastic init state\n",
    "ENV.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8bdad6-2fe6-4dd4-9399-07e44ed1e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr(env=ENV):\n",
    "    \"\"\"quick render fix assuming env's render_mode='rgb_array' \"\"\"\n",
    "    # plt.figure(figsize=(5,10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(env.render())\n",
    "               \n",
    "def act(action, env=ENV):\n",
    "    \"\"\"filters unnecessary output\"\"\"\n",
    "    return env.step(action)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491863d3-e621-4e80-aa2b-97ed10798d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.4070817 , -0.00040907], dtype=float32), -0.009, False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state = act(np.array([0.3])) # [state, reward, done, info, ...]\n",
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8f4007-cce1-4583-b424-bcf178bdfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRandAgent():\n",
    "    \"\"\"baseline agent that performs random actions=np.arrays with shape (1,) and values within [-1, 1]\"\"\"\n",
    "    def __init__(self, d_actions=DIM_A):\n",
    "        self.d_actions = d_actions\n",
    "        \n",
    "    def act(self, state):\n",
    "        action = np.random.uniform(low=-1, high=1, size=self.d_actions)\n",
    "        # print('RANDOM!!')\n",
    "        return action\n",
    "\n",
    "    def walk(self, max_length, render=False, **actkwargs):\n",
    "        \"\"\"take max_length actions by agent N\"\"\"\n",
    "        states, actions, rewards = [], [], []\n",
    "        # initialization state\n",
    "        state = ENV.reset()[0]\n",
    "        for i in range(max_length):\n",
    "            # perform an action\n",
    "            action = self.act(state, **actkwargs)\n",
    "            new_state, reward, done = act(action)\n",
    "            # log \n",
    "            actions.append(action)\n",
    "            states.append(state) # append OLD state, everything breaks if you start from new\n",
    "            rewards.append(reward)\n",
    "            state = new_state\n",
    "            # continuos visualization w/ proper interrupt\n",
    "            if render:\n",
    "                try:\n",
    "                    rr()\n",
    "                    display.display(plt.gcf())\n",
    "                    display.clear_output(wait=True)\n",
    "                    time.sleep(1e-4)\n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "            if done:\n",
    "                break\n",
    "        trajectory = {'s': states,\n",
    "                        'a': actions,\n",
    "                            'r': rewards,}\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce50f0d-b7e8-4e3c-b496-271e74ed5a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5954364017328574"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = CRandAgent()\n",
    "results = agent.walk(max_length=20, render=True)\n",
    "sum(results['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b5bb1f-03bd-4c19-a13a-2decc138a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxillary functions\n",
    "def lin_ann_rate(i, n_total):\n",
    "    return 1 - i / n_total\n",
    "\n",
    "def exp_ann_rate(i, thr=0.0001, la=2/300, drop=0.001):\n",
    "    \"\"\"exponential decay with i --> +inf, provides descending values within range [expl_thr, 1],\n",
    "        la=0.01 means ~36% left after 100 iterations, results < drop value are zeroed\"\"\"\n",
    "    exp = np.exp if isinstance(i, np.ndarray) else torch.exp\n",
    "    result = thr + (1 - thr) * exp(- la * i)\n",
    "    if drop:\n",
    "        result[result <= drop] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2744d8c2-cba5-4f3c-8712-9944e45f83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyNNCAgent(CRandAgent):\n",
    "    def __init__(self, d_states=DIM_S, d_actions=DIM_A, hidden_d=(16, 4), device=DEVICE):\n",
    "        \"\"\"CrossEntropy algorithm actor, optimizes expected reward by policy, given by neural network\"\"\"\n",
    "        super().__init__(d_actions)\n",
    "        self.d_states = d_states\n",
    "        self.var = 1\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = device\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=self.d_states, out_features=hidden_d[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_d[0], hidden_d[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_d[1], d_actions))\n",
    "        \n",
    "        self.log = []\n",
    "        self.hp = {}\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"policy = action given by tanh(network output) + random normal(positive) noise within [0..1] \n",
    "            otherwise this policy would be almost completely deterministic (as NN is except its initialization)\n",
    "            extra tanh here is just to fit result into action space min max limits\"\"\"\n",
    "        with torch.inference_mode():\n",
    "            action = nn.functional.tanh(nn.functional.tanh(self.model(torch.Tensor(state)).detach()) + self.var * torch.randn(self.d_actions))\n",
    "            # torch.Tensor(self.d_actions).uniform_(0, 1)\n",
    "            #torch.randn(self.d_actions)\n",
    "        return action.numpy()\n",
    "\n",
    "    def learning_curve(self, show_max=True, ax=None):\n",
    "        \"\"\"plots rewards vs iterations of algorithm\"\"\"\n",
    "        ax = sns.lineplot(self.log, linewidth=1.0, ax=ax, label=f\"lr={self.hp['lr']}\")\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.set_title(f\"Mean reward over {self.hp['n_trajectories']} trajectories of length < {self.hp['max_length']}\", fontsize = 10)\n",
    "        ax.set_xlabel('iterations - 1')\n",
    "        # ax.set_yscale('symlog')\n",
    "        ax.legend()\n",
    "        if show_max:\n",
    "            ax.axhline(y=max(self.log), color='r', linestyle='-', linewidth=0.5)\n",
    "        return ax\n",
    "        \n",
    "        \n",
    "    def fit(self, n_iterations, max_n_epochs, noise_var=1, lr=0.01, n_trajectories=100, max_length=50, q=0.8, verbose=None):\n",
    "        \"\"\"\n",
    "        CE Algorithm has 2 steps per iteration: evaluate policy, improve policy\n",
    "        Our goal is to maximize expected reward ER which is unreachable => approximated\n",
    "        \n",
    "        n_trajectories (w/ length <= max_length) defines quality of ER approximation\n",
    "        0<q<1 controls rejected quantile of trajectories\n",
    "\n",
    "        max_n_epochs controls max possible NN training epochs per each iteration\n",
    "\n",
    "        lr defines learning rate of built-in Adam optimizer\n",
    "        \n",
    "        verbose>0 sets up a period of learning process rendering\n",
    "\n",
    "        NB: .fit internally uses .act method of child class(this), doesn't inherit parental\n",
    "        \"\"\"\n",
    "        # save fitting hyperparameters for comparison\n",
    "        ap = locals()\n",
    "        self.hp = {k: ap[k] for k in ap.keys() - ['self', 'verbose', 'n_iterations', 'n_epochs']}\n",
    "        self.model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        iterations_pbar = tqdm.trange(n_iterations, position=0, leave=True, colour=\"#a2d2ff\")\n",
    "        dh = display.display(display_id=True)\n",
    "        var_0 = noise_var\n",
    "        vars = []\n",
    "        for i in iterations_pbar:\n",
    "            self.model.eval()\n",
    "            # policy evaluation (act with current policy or sample n_det deterministic from that one)\n",
    "            trajectories = [self.walk(max_length=max_length) for t in range(n_trajectories)]\n",
    "            rewards = np.stack([np.sum(t['r']) for t in trajectories])\n",
    "            avg_reward = np.mean(rewards)\n",
    "            self.log.append(avg_reward)\n",
    "\n",
    "            # policy improvement\n",
    "            # get q-quantile of current reward distribution and filter out better trajectories\n",
    "            gamma = np.quantile(rewards, q)\n",
    "            elite_ids = (rewards > gamma).nonzero()[0]\n",
    "            if elite_ids.any():\n",
    "                # extract (lists of) state and (corresponding) action tensors from elite trajectories\n",
    "                states_l, actions_l = zip(*((np.stack(trajectories[ei]['s']), np.stack(trajectories[ei]['a'])) for ei in elite_ids))\n",
    "                states, actions = torch.Tensor(np.concatenate(states_l)).to(self.device), torch.Tensor(np.concatenate(actions_l)).to(self.device)\n",
    "                epochs_pbar = [0] if (max_n_epochs == 1 or i==0) else tqdm.trange(n_epochs, position=1, leave=False, colour=\"#ffc8dd\") # order matters\n",
    "                self.model.train()\n",
    "                for e in epochs_pbar:\n",
    "                    # forward pass\n",
    "                    pred_actions = self.model(states)\n",
    "                    loss = self.loss(pred_actions, actions)\n",
    "                    # backward pass\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # noise variance (descends from var_0 to 0)\n",
    "                self.var = var_0 * lin_ann_rate(i, n_total=n_iterations)\n",
    "                vars.append(self.var)\n",
    "                # less stochastic gradients (ascending from 1 to max_n_epochs)\n",
    "                n_epochs = 1 + round((1 - exp_ann_rate(torch.Tensor([i]), thr=0, la=2/n_iterations, drop=None).item()) * (max_n_epochs - 1))\n",
    "                iterations_pbar.set_postfix_str(f'avg reward: {avg_reward.item():.2f}, loss: {loss.detach().item():.2e}, var: {self.var:.2f}, n_epochs: {n_epochs}', refresh=True)\n",
    "            \n",
    "            # visualization (plotting starts after at least 1 iteration)\n",
    "            if verbose and i > 0 and (i + 1) % verbose == 0:\n",
    "                # print(f\"iteration {i + 1}, mean total reward: {avg_reward}\")\n",
    "                figure, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "                ax = self.learning_curve(ax=axes[0])\n",
    "                \n",
    "                ax2 = ax.twinx()\n",
    "                ax2.tick_params(axis='y', labelcolor='slateblue')\n",
    "                sns.lineplot(vars, linewidth=0.5, ax=ax2, label=\"variance\", color='slateblue')\n",
    "                \n",
    "                ax = sns.histplot(rewards, kde=False, bins=20, ax=axes[1])\n",
    "                ax.axvline(gamma, 0, 20, color='r')\n",
    "                ax.set_xlabel('Rewards')\n",
    "                ax.set_title(f'Current distribution of rewards and its {q:.2f}-quantile ', fontsize = 10)\n",
    "                \n",
    "                dh.update(plt.gcf())\n",
    "                plt.close() # because plt.clf() is spurious\n",
    "        return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3306e1b-b934-4c32-b0fb-289e3e77935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f290486769a74abaad64728a73392930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_nnc = CrossEntropyNNCAgent()\n",
    "agent_nnc.fit(n_iterations=100, max_n_epochs=10, noise_var=1, lr=0.01, n_trajectories=60, max_length=1000, q=0.8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ef79e-9d1f-47bf-928c-c7da88d460f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = agent_nnc.walk(max_length=100, render=False)\n",
    "sum(results['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f56305-3c31-45b5-9429-68e667cc5d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
